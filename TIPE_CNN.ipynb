{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5af979-4cea-4fb5-9ca7-7eac955b4648",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CheXpert Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decf8cc-51a2-456c-a447-f3e7ed0dcd35",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8935e5-ddde-4ae9-805a-e90b7910976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import fiftyone as fo\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62086749-98be-4c7d-82c1-c1ee06085602",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6364b5f2-d7ec-48c7-b049-fed71bb61a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "max_data = 50000\n",
    "\n",
    "dataset_dir = \"D:/Arthur/TIPE/data\"\n",
    "img_size = (224, 224, 1)\n",
    "big_batch_size = 320\n",
    "\n",
    "# Classes (only 5 of them)\n",
    "classes = [\"Cardiomegaly\", \n",
    "           \"Edema\",\n",
    "           \"Consolidation\", \n",
    "           \"Atelectasis\", \n",
    "           \"Pleural Effusion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669eca5-8661-48b2-8fc6-f71c6a8c36dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f5e22-97da-45ed-b277-2f3bd980d7e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd2118-1d17-4d4d-b3fc-61d70fb0c3e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 'deprecated' - Load the entire dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6badc6f5-ae32-4d22-80e2-094a18b60393",
   "metadata": {
    "tags": []
   },
   "source": [
    "Récupère les images du dataset, les labels stockés dans un .csv, puis met tout en forme.\n",
    "Les images sont standardisées en format et en valeurs."
   ]
  },
  {
   "cell_type": "raw",
   "id": "60eea8ed-92d6-4f19-ae96-b3b5f8e3f40b",
   "metadata": {},
   "source": [
    "max_size = 10000\n",
    "\n",
    "# Récupère les fichiers csv\n",
    "csv_train = pd.read_csv(\"{}/train.csv\".format(dataset_dir), index_col=0)\n",
    "csv_test = pd.read_csv(\"{}/valid.csv\".format(dataset_dir), index_col=0)\n",
    "\n",
    "size_train, size_valid = len(csv_train), len(csv_test)\n",
    "\n",
    "images_train = []\n",
    "targets_train = []\n",
    "images_test = []\n",
    "targets_test = []\n",
    "    \n",
    "### Créer les arrays d'images et de targets associées ###\n",
    "to_do = max_size + size_valid - 1\n",
    "i = 0\n",
    "\n",
    "# Train\n",
    "for path in csv_train.index:\n",
    "    \n",
    "    # On ne traite que les images frontales\n",
    "    if csv_train.loc[path][\"Frontal/Lateral\"] == \"Frontal\":\n",
    "    \n",
    "        img_path = \"{}/{}\".format(dataset_dir.split(\"CheXpert-v1.0-small\")[0], path).replace(\"/\", \"\\\\\")\n",
    "\n",
    "        # Redimensionne les images\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((img_size[0], img_size[1]), Image.ANTIALIAS)\n",
    "        img = np.asarray(img, dtype=\"float32\") # float32 pour conv\n",
    "        \n",
    "        images_train.append(img)\n",
    "\n",
    "        target = np.array([1 if csv_train.loc[path][c] == 1.0 else 0 for c in classes])\n",
    "        targets_train.append(target)\n",
    "                \n",
    "        \n",
    "    # Barre de chargement\n",
    "    done = i/to_do\n",
    "    print(\"Fetching : {}% |{}| {}/{}\".format(int(done*1000)/10, \"#\"*int(done*20) + \"-\"*(20-int(done*20)), i, to_do), end=\"\\r\")\n",
    "    i+=1\n",
    "    \n",
    "    if i >=max_size:\n",
    "        break\n",
    "\n",
    "# Test\n",
    "for path in csv_test.index:\n",
    "    \n",
    "    # On ne traite que les images frontales\n",
    "    if csv_test.loc[path][\"Frontal/Lateral\"] == \"Frontal\":\n",
    "    \n",
    "        img_path = \"{}/{}\".format(dataset_dir.split(\"CheXpert-v1.0-small\")[0], path).replace(\"/\", \"\\\\\")\n",
    "\n",
    "        # Redimensionne les images\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((img_size[0], img_size[1]), Image.ANTIALIAS)\n",
    "        img = np.asarray(img, dtype=\"float32\") # float32 pour conv\n",
    "        \n",
    "        images_test.append(img)\n",
    "\n",
    "        target = np.array([1 if csv_test.loc[path][c] == 1.0 else 0 for c in classes])\n",
    "        targets_test.append(target)\n",
    "                \n",
    "\n",
    "    # Barre de chargement\n",
    "    done = i/to_do\n",
    "    print(\"Fetching : {}% |{}| {}/{}\".format(int(done*1000)/10, \"#\"*int(done*20) + \"-\"*(20-int(done*20)), i, to_do), end=\"\\r\")\n",
    "    i+=1\n",
    "\n",
    "print()\n",
    "\n",
    "### Pré-processing des données ###\n",
    "print(\"Preprocessing...\", end=\"\\r\")\n",
    "\n",
    "images_train = np.array(images_train)\n",
    "targets_train = np.array(targets_train)\n",
    "images_test = np.array(images_test)\n",
    "targets_test = np.array(targets_test)\n",
    "\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "scaled_images_train = scaler.fit_transform(images_train.reshape(-1, img_size[0]*img_size[1]*img_size[2]))\n",
    "scaled_images_test = scaler.transform(images_test.reshape(-1, img_size[0]*img_size[1]*img_size[2]))\n",
    "\n",
    "del images_train\n",
    "del images_test\n",
    "\n",
    "scaled_images_train = scaled_images_train.reshape(-1, img_size[0], img_size[1], img_size[2])\n",
    "scaled_images_test = scaled_images_test.reshape(-1, img_size[0], img_size[1], img_size[2])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((scaled_images_train, targets_train))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((scaled_images_test, targets_test))\n",
    "\n",
    "print(\"# Data Ready ! #\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8697fc3-90e5-4e99-9570-390e2572f152",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 'done' - Preprocessing data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14a67d19-59b0-4729-8aac-2062c6284e07",
   "metadata": {},
   "source": [
    "### Loading data ###\n",
    "\n",
    "csv_train = pd.read_csv(\"{}/CheXpert-v1.0-small/train.csv\".format(dataset_dir), index_col=0)\n",
    "csv_train = csv_train.loc[csv_train[\"Frontal/Lateral\"] == \"Frontal\"]\n",
    "\n",
    "csv_valid = pd.read_csv(\"{}/CheXpert-v1.0-small/valid.csv\".format(dataset_dir), index_col=0)\n",
    "csv_valid = csv_valid.loc[csv_valid[\"Frontal/Lateral\"] == \"Frontal\"]\n",
    "\n",
    "# We discard data with an uncertainty label\n",
    "for c in classes:\n",
    "    csv_train.drop(csv_train[csv_train[c] == -1.0].index, inplace=True)\n",
    "    csv_valid.drop(csv_valid[csv_valid[c] == -1.0].index, inplace=True)\n",
    "\n",
    "size_train, size_valid = len(csv_train), len(csv_valid)\n",
    "\n",
    "images_train = np.zeros((size_train, img_size[0], img_size[1], img_size[2]), dtype=\"float32\")\n",
    "targets_train = np.zeros((size_train, len(classes)), dtype=\"float32\")\n",
    "images_valid = np.zeros((size_valid, img_size[0], img_size[1], img_size[2]), dtype=\"float32\")\n",
    "targets_valid = np.zeros((size_valid, len(classes)), dtype=\"float32\")\n",
    "    \n",
    "### Loads the dataset as arrays ###\n",
    "to_do = size_train + size_valid - 1\n",
    "i = 0\n",
    "\n",
    "# Train\n",
    "for path in csv_train.index:\n",
    "    \n",
    "    img_path = \"{}/{}\".format(dataset_dir.split(\"CheXpert-v1.0-small\")[0], path).replace(\"/\", \"\\\\\")\n",
    "\n",
    "    # Resizing\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((img_size[0], img_size[1]), Image.ANTIALIAS)\n",
    "    img = np.asarray(img, dtype=\"float32\") # float32 for conv\n",
    "    img = img.reshape(img_size[0], img_size[1], img_size[2])\n",
    "\n",
    "    target = np.array([1 if csv_train.loc[path][c] == 1.0 else 0 for c in classes])\n",
    "\n",
    "    targets_train[i] = target\n",
    "    images_train[i] = img\n",
    "        \n",
    "    # Loading bar\n",
    "    done = i/to_do\n",
    "    print(\"Fetching : {}% |{}| {}/{}\".format(int(done*1000)/10, \"#\"*int(done*20) + \"-\"*(20-int(done*20)), i, to_do), end=\"\\r\")\n",
    "    i+=1\n",
    "    \n",
    "# Valid\n",
    "for path in csv_valid.index:\n",
    "    \n",
    "    img_path = \"{}/{}\".format(dataset_dir.split(\"CheXpert-v1.0-small\")[0], path).replace(\"/\", \"\\\\\")\n",
    "\n",
    "    # Resizing\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((img_size[0], img_size[1]), Image.ANTIALIAS)\n",
    "    img = np.asarray(img, dtype=\"float32\") # float32 pour conv\n",
    "    img = img.reshape(img_size[0], img_size[1], img_size[2])\n",
    "    \n",
    "    target = np.array([1 if csv_valid.loc[path][c] == 1.0 else 0 for c in classes])\n",
    "    \n",
    "    targets_valid[i-size_train] = target\n",
    "    images_valid[i-size_train] = img\n",
    "\n",
    "    # Loading bar\n",
    "    done = i/to_do\n",
    "    print(\"Fetching : {}% |{}| {}/{}\".format(int(done*1000)/10, \"#\"*int(done*20) + \"-\"*(20-int(done*20)), i, to_do), end=\"\\r\")\n",
    "    i+=1\n",
    "\n",
    "print()\n",
    "print(\"# Data Loaded #\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09dc9823-bbc4-4957-9dd3-0bae3bc9556a",
   "metadata": {},
   "source": [
    "### Processing data ###\n",
    "\n",
    "# Reshaping 1 (inplace)\n",
    "print(\"Processing : First Reshaping...\")\n",
    "images_train.shape = (-1, img_size[0]*img_size[1]*img_size[2])\n",
    "images_valid.shape = (-1, img_size[0]*img_size[1]*img_size[2])\n",
    "\n",
    "# Normalisation des données (inplace)\n",
    "print(\"Processing : Normalizing...\")\n",
    "m = images_train.mean()\n",
    "std = images_train.std()\n",
    "\n",
    "images_train-=m\n",
    "images_train/=std\n",
    "\n",
    "images_valid-=m\n",
    "images_valid/=std\n",
    "\n",
    "# Reshaping 2 (inplace)\n",
    "print(\"Processing : Second Reshaping...\")\n",
    "images_train.shape = (-1, img_size[0], img_size[1], img_size[2])\n",
    "images_valid.shape = (-1, img_size[0], img_size[1], img_size[2])\n",
    "\n",
    "print(\"# Data Processed #\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6905c735-e658-444d-ba23-f42b0db97a61",
   "metadata": {},
   "source": [
    "### Saving the data on files ###\n",
    "\n",
    "to_do = size_train // big_batch_size\n",
    "\n",
    "# Training data\n",
    "os.chdir(dataset_dir+\"/NPZ/train\")\n",
    "\n",
    "for i in range(to_do):\n",
    "    \n",
    "    big_batch = images_train[i*big_batch_size : (i+1)*big_batch_size]\n",
    "    targets = targets_train[i*big_batch_size : (i+1)*big_batch_size]\n",
    "    \n",
    "    np.savez(\"batch_{}.npz\".format(i), images=big_batch, targets=targets)\n",
    "    \n",
    "    # Loading bar\n",
    "    done = i/to_do\n",
    "    print(\"Saving : {}% |{}| {}/{}\".format(int(done*1000)/10, \"#\"*int(done*20) + \"-\"*(20-int(done*20)), i, to_do), end=\"\\r\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Validation data\n",
    "os.chdir(\"../valid\")\n",
    "\n",
    "np.savez(\"batch_0.npz\", images=images_valid, targets=targets_valid)\n",
    "\n",
    "print(\"### Data Saved ! ###\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ddb925-e1d5-4afa-8b30-5d9e7ce919d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create DataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d2137-87c0-43fb-a44e-171dfbe19d79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 'deprecated' - Directly loading images"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb1d6492-10e5-4b77-99be-05aa7742fa58",
   "metadata": {},
   "source": [
    "Le générateur récupère les données par batch lorsqu'il est appelé par model.fit."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4608b4a5-9bc5-4284-a903-a1889ec05b0c",
   "metadata": {},
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Load data directly from the dataset (images).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size, dataset_directory):\n",
    "        self.batch_size = batch_size\n",
    "        self.directory = dataset_directory\n",
    "        \n",
    "        self.csv = pd.read_csv(self.directory, index_col=0)\n",
    "        self.csv = self.csv.loc[self.csv[\"Frontal/Lateral\"] == \"Frontal\"][:max_data]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.csv) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_csv = self.csv[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        images = []\n",
    "        targets = []\n",
    "        \n",
    "        for path in batch_csv.index:\n",
    "            img_path = \"{}/{}\".format(self.directory.split(\"CheXpert-v1.0-small\")[0], path).replace(\"/\", \"\\\\\")\n",
    "\n",
    "            # Images\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize((img_size[0], img_size[1]), Image.ANTIALIAS)\n",
    "            img = np.asarray(img, dtype=\"float32\") # float32 pour conv\n",
    "            img = img.reshape(img_size[0], img_size[1], img_size[2])\n",
    "            images.append(img)\n",
    "            \n",
    "            # Targets\n",
    "            target = np.array([1 if batch_csv.loc[path][c] == 1.0 else 0 for c in classes])\n",
    "            targets.append(target)\n",
    "\n",
    "        return np.array(images), np.array(targets)\n",
    "\n",
    "TrainingGenerator = DataGenerator(batch_size=batch_size, dataset_directory=dataset_dir+\"/CheXpert-v1.0-small/train.csv\")\n",
    "ValidationGenerator = DataGenerator(batch_size=batch_size, dataset_directory=dataset_dir+\"/CheXpert-v1.0-small/valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a758e-bd4b-47fe-85e9-285e3db38c9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Loading *.npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8555294-9f83-4632-be1c-dafe02c1af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variante pour les fichiers npz\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Load data from pre-processed *.npz files (normalized, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, batch_size, dataset_directory):\n",
    "        self.batch_size = batch_size\n",
    "        self.directory = dataset_directory\n",
    "        self.list_IDs = os.listdir(self.directory)\n",
    "   \n",
    "    def __len__(self):\n",
    "        return min(len(self.list_IDs) * big_batch_size, max_data) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        big_batch = (index * self.batch_size) // big_batch_size\n",
    "        \n",
    "        np_file = np.load(self.directory+\"/batch_{}.npz\".format(big_batch))\n",
    "        \n",
    "        return np_file[\"images\"][(index*self.batch_size)%big_batch_size : ((index*self.batch_size)%big_batch_size)+self.batch_size], \\\n",
    "               np_file[\"targets\"][(index*self.batch_size)%big_batch_size : ((index*self.batch_size)%big_batch_size)+self.batch_size]\n",
    "        \n",
    "TrainingGenerator = DataGenerator(batch_size=batch_size, dataset_directory=dataset_dir+\"/NPZ/train\")\n",
    "ValidationGenerator = DataGenerator(batch_size=batch_size, dataset_directory=dataset_dir+\"/NPZ/valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef1847-b224-40a3-a53e-178af992a3d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1852259-cb5f-4c9b-9199-856ad8ed3c09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8439472b-4c17-48f3-b21b-9964c216efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_Head(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Classification_Head, self).__init__()\n",
    "        \n",
    "        self.list_layers = [\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(4096, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(4096, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(len(classes), activation='sigmoid')\n",
    "        ]\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        for layer in self.list_layers :\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218a82e-945a-4406-8186-dccea7188de5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### AlexNet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "326096bd-ef69-473c-82da-1c0846af1817",
   "metadata": {},
   "source": [
    "class AlexNet_CONV(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AlexNet_CONV, self).__init__()\n",
    "        \n",
    "        self.list_layers = [\n",
    "            tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224, 224, 1)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    \n",
    "            tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    \n",
    "            tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))\n",
    "        ]\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        for layer in self.list_layers :\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8994b9-565c-4200-9e3d-d39810c99b9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### VGG16"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0ec17f2-971a-4e2a-8cdf-eb88e32f7826",
   "metadata": {},
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding=\"same\", input_shape=(224, 224, 1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    \n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(len(classes), activation='sigmoid')\n",
    "], name=\"VGG16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6c47a-0fb8-4f45-80dd-d339f5ae7dc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Compile functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "698731b8-2479-4ea4-8a59-e92ab1bf290d",
   "metadata": {
    "tags": []
   },
   "source": [
    "On utilise BinaryCrossentropy car la prédiction finale n'est pas réduite à une seule classe mais bien à plusieurs.\n",
    "\n",
    "L -> nombre de classes\n",
    "p = [p1, ..., pL] -> prediction\n",
    "t = [t1, ..., tL] -> target\n",
    "\n",
    "Loss = -1/L * Somme{ ti*log(pi) + (1-ti)*log(1-pi) }\n",
    "\n",
    "Si ti = 1 -> seul le terme ti*log(pi) compte, on veut maximiser (il faut pi = 1)\n",
    "Si ti = 0 -> seul le terme (1-ti)*log(1-pi) compte, on veut maximiser (il faut 1-pi = 1)\n",
    "\n",
    "On divise par L parce que, à l'inverse de CategoricalCrossentropy, il n'y a pas 1 valeur qui compte dans la somme mais bien toutes.\n",
    "\n",
    "Le -1 permet de diminuer le loss et non de l'augmenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98895983-0872-4950-a3c8-77f176a1b06d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(0.01, decay_steps=1000, decay_rate=0.96, staircase=True)\n",
    "def compile(model, lr) :\n",
    "    \n",
    "    global loss_object\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "    global optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # For graph mode\n",
    "    global train_loss\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    global valid_loss\n",
    "    valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "    global train_accuracy\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "    global valid_accuracy\n",
    "    valid_accuracy = tf.keras.metrics.CategoricalAccuracy(name='valid_accuracy')\n",
    "\n",
    "    model.compile(\n",
    "            loss=loss_object,\n",
    "            optimizer=optimizer,\n",
    "            metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d9a1b-af3e-4143-99c6-b3673eb7529a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe22a6-32c6-4b1a-8ee5-6739b0923b9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b641d-36a5-4a73-8860-e17c77cdaafb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Step functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ca62e1-b322-4454-bc01-ff386265c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(images, targets):\n",
    "\n",
    "    train_vars = model.trainable_variables\n",
    "    accum_gradient = [tf.zeros_like(var) for var in train_vars]\n",
    "  \n",
    "    for image, target in zip(images, targets) :\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = model(image)\n",
    "            target.shape = model(image).shape\n",
    "            loss = loss_object(target, prediction)\n",
    "        \n",
    "        train_loss(loss)\n",
    "        train_accuracy(target, prediction) \n",
    "\n",
    "        gradients = tape.gradient(loss, train_vars)\n",
    "        accum_gradient = [(acum_grad+grad) for acum_grad, grad in zip(accum_gradient, gradients)]\n",
    "    \n",
    "    accum_gradient = [grad/len(images) for grad in accum_gradient]\n",
    "    \n",
    "    optimizer.apply_gradients(zip(accum_gradient, model.trainable_variables))\n",
    "\n",
    "#@tf.function\n",
    "def valid_step(images, targets):\n",
    "    \n",
    "    predictions = model(images)\n",
    "    loss = loss_object(targets, predictions)\n",
    "    \n",
    "    valid_loss(loss)\n",
    "    valid_accuracy(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831cf6c7-9086-4e5b-b157-d003c11c8b69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Boucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37063635-41d8-45de-98d1-9eb1aec24272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "\n",
    "    b = 0 # Permet de tracker où on en est dans les batchs\n",
    "    history = {'accuracy':[], 'loss':[], 'val_accuracy':[], 'val_loss':[]}\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # TRAINING\n",
    "        for images, targets in TrainingGenerator:\n",
    "\n",
    "            train_step(images, targets)\n",
    "\n",
    "            template = '\\r Batch {}/{}, Loss: {}, Accuracy: {}'\n",
    "            print(template.format(b, len(TrainingGenerator), train_loss.result(), train_accuracy.result()*100), end=\"\")\n",
    "\n",
    "            b += batch_size\n",
    "\n",
    "        # VALIDATION\n",
    "        for images, targets in ValidationGenerator:\n",
    "            valid_step(images, targets)\n",
    "\n",
    "        template = '\\nEpoch {}, Valid Loss: {}, Valid Accuracy: {}'\n",
    "        print(template.format(\n",
    "            epoch+1,\n",
    "            valid_loss.result(), \n",
    "            valid_accuracy.result()*100)\n",
    "        )\n",
    "        \n",
    "        # On stocke les accumulateurs dans l'history\n",
    "        history['accuracy'].append(train_accuracy.result())\n",
    "        history['loss'].append(train_loss.result())\n",
    "        history['val_accuracy'].append(valid_accuracy.result())\n",
    "        history['val_loss'].append(valid_loss.result())\n",
    "        \n",
    "        # On reset les accumulateurs\n",
    "        valid_loss.reset_states()\n",
    "        valid_accuracy.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        train_loss.reset_states()\n",
    "        b = 0\n",
    "        print(\"\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfb559d-bac2-4dba-8071-34ddd03337ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Post-training functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101875ed-6957-4e8a-8f3d-4ad18497b1bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### save_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9eec85d-867e-478d-a9b5-03ad0d881cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training(history) :\n",
    "\n",
    "    os.chdir(dataset_dir+\"/training_sessions\")\n",
    "\n",
    "    # Create a folder for the training session\n",
    "    i=0\n",
    "    error = True\n",
    "    while error:\n",
    "        try:\n",
    "            fd = \"{}_{}k_{}-epochs_{}\".format(model.name, str(max_data)[:-3], str(epochs), str(i))\n",
    "            os.mkdir(\"{}\".format(fd))\n",
    "        except FileExistsError:\n",
    "            i+=1\n",
    "        else:\n",
    "            error=False\n",
    "\n",
    "    os.chdir(dataset_dir+\"/training_sessions/{}\".format(fd))\n",
    "\n",
    "    # Report file\n",
    "    with open(\"training_report.txt\", \"w\") as f:\n",
    "        f.write(\"TRAINING REPORT :\\n\\n\")\n",
    "        f.write(\"epochs = \" + str(epochs))\n",
    "        f.write(\"\\nbatch_size = \" + str(batch_size))\n",
    "        f.write(\"\\nlearning_rate = \" + str(learning_rate))\n",
    "        f.write(\"\\nmax_data = \" + str(max_data))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\nSummary :\\n\")\n",
    "        model.summary(print_fn=lambda x : f.write(\"\\n\" + x))\n",
    "\n",
    "    # Retrieve curves\n",
    "    loss_curve = history[\"loss\"]\n",
    "    acc_curve = history[\"accuracy\"]\n",
    "    loss_val_curve = history[\"val_loss\"]\n",
    "    acc_val_curve = history[\"val_accuracy\"]\n",
    "\n",
    "    # Loss fig\n",
    "    plt.plot(loss_curve, \"r\", label=\"Train\")\n",
    "    plt.plot(loss_val_curve, \"g\", label=\"Validation\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.savefig(\"loss.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    # Accuracy fig\n",
    "    plt.plot(acc_curve, \"r\", label=\"Train\")\n",
    "    plt.plot(acc_val_curve, \"g\", label=\"Validation\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.savefig(\"accuracy.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    # Save the model\n",
    "    model.save(\"model.h5\")\n",
    "\n",
    "    print(\"# Model Saved ! #\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649696a-5ec6-4d6b-8c0f-38684abdb827",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### visualize_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdffdcc-bab2-4960-bfc7-9b51b846f35b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_training(history) :\n",
    "    \n",
    "    # Retrieve curves\n",
    "    loss_curve = history[\"loss\"]\n",
    "    acc_curve = history[\"accuracy\"]\n",
    "\n",
    "    loss_val_curve = history[\"val_loss\"]\n",
    "    acc_val_curve = history[\"val_accuracy\"]\n",
    "\n",
    "    ### Plot the fig ###\n",
    "\n",
    "    # Loss\n",
    "    plt.plot(loss_curve, \"r\", label=\"Train\")\n",
    "    plt.plot(loss_val_curve, \"g\", label=\"Validation\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(\"Loss\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.plot(acc_curve, \"r\", label=\"Train\")\n",
    "    plt.plot(acc_val_curve, \"g\", label=\"Validation\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(\"Accuracy\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7db9d9-b0bb-4b72-855d-0cee929a38f5",
   "metadata": {},
   "source": [
    "# LAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e71c00-ae29-464b-8be7-b1eb3c35a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_extractor = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "classification_head = Classification_Head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a4cdf58-096b-4b06-991f-4ca03afa90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.base = pretrained_extractor\n",
    "        self.classification = classification_head\n",
    "        \n",
    "        self.base.trainable = False\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        x = tf.image.grayscale_to_rgb(x)\n",
    "        x = tf.reshape(x, shape=(-1,224,224,3))\n",
    "        x = self.base(x)\n",
    "        x = self.classification(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f09290a-4224-4d79-96d7-50ee232fb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model()\n",
    "compile(model, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "847044e6-091a-4e1a-bdcc-c1a15ef6e624",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 0/1562, Loss: 0.8070566058158875, Accuracy: 15.625"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5524/3047492559.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msave_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvisualize_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5524/3822158606.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTrainingGenerator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\r Batch {}/{}, Loss: {}, Accuracy: {}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5524/979117346.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(images, targets)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0maccum_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macum_grad\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0macum_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccum_gradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0maccum_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccum_gradient\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5524/979117346.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0maccum_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macum_grad\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0macum_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccum_gradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0maccum_gradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maccum_gradient\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1698\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1699\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1700\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    452\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "history = train(model)\n",
    "\n",
    "save_training(history1)\n",
    "visualize_training(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321a902a-77c1-4d76-a995-57ed7b59f7c7",
   "metadata": {},
   "source": [
    "### Loading previsous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c67390-6832-4f91-92ed-6e25465315fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model = tf.keras.models.load_model(\"*.h5\")\n",
    "len(TrainingGenerator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
