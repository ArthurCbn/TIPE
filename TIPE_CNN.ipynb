{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "TIPE_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurCbn/TIPE/blob/main/TIPE_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d5af979-4cea-4fb5-9ca7-7eac955b4648"
      },
      "source": [
        "# CheXpert Classification"
      ],
      "id": "4d5af979-4cea-4fb5-9ca7-7eac955b4648"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4decf8cc-51a2-456c-a447-f3e7ed0dcd35"
      },
      "source": [
        "### Dependencies"
      ],
      "id": "4decf8cc-51a2-456c-a447-f3e7ed0dcd35"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba8935e5-ddde-4ae9-805a-e90b7910976d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "id": "ba8935e5-ddde-4ae9-805a-e90b7910976d",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VovnKy_NrWpl",
        "outputId": "45c0bb38-8c93-44c7-9be7-ccb1298098a0"
      },
      "source": [
        "os.getcwd()"
      ],
      "id": "VovnKy_NrWpl",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "942f5e22-97da-45ed-b277-2f3bd980d7e8"
      },
      "source": [
        "## Data Fetching"
      ],
      "id": "942f5e22-97da-45ed-b277-2f3bd980d7e8"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "6badc6f5-ae32-4d22-80e2-094a18b60393"
      },
      "source": [
        "Récupère les images du dataset, les labels stockés dans un .csv, puis met tout en forme.\n",
        "Les images sont standardisées en format et en valeurs."
      ],
      "id": "6badc6f5-ae32-4d22-80e2-094a18b60393"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "80f2d637-800e-4493-a898-1242f5db9567",
        "outputId": "f9f3d931-b6c4-47df-a189-b28f594facee"
      },
      "source": [
        "dataset_dir = \"C:/Users/arthu/datasets/CheXpert-v1.0-small\"\n",
        "img_size = (224, 224, 1)\n",
        "max_size = 5000\n",
        "\n",
        "# Récupère les fichiers csv\n",
        "csv_train = pd.read_csv(\"{}/train.csv\".format(dataset_dir), index_col=0)\n",
        "csv_test = pd.read_csv(\"{}/valid.csv\".format(dataset_dir), index_col=0)\n",
        "\n",
        "size_train, size_valid = len(csv_train), len(csv_test)\n",
        "\n",
        "# Classes\n",
        "classes = [\"Enlarged Cardiomediastinum\", \n",
        "           \"Cardiomegaly\", \n",
        "           \"Lung Opacity\", \n",
        "           \"Lung Lesion\",\n",
        "           \"Edema\",\n",
        "           \"Consolidation\", \n",
        "           \"Pneumonia\", \n",
        "           \"Atelectasis\", \n",
        "           \"Pneumothorax\", \n",
        "           \"Pleural Effusion\", \n",
        "           \"Pleural Other\",\n",
        "           \"Fracture\"]\n",
        "\n",
        "images_train = []\n",
        "targets_train = []\n",
        "images_test = []\n",
        "targets_test = []\n",
        "    \n",
        "### Créer les arrays d'images et de targets associées ###\n",
        "to_do = max_size + size_valid - 1\n",
        "i = 0\n",
        "\n",
        "# Train\n",
        "for path in csv_train.index:\n",
        "    \n",
        "    # On ne traite que les images frontales\n",
        "    if csv_train.loc[path][\"Frontal/Lateral\"] == \"Frontal\":\n",
        "    \n",
        "        img_path = \"{}/{}\".format(dataset_dir.split(\"CheXpert-v1.0-small\")[0], path).replace(\"/\", \"\\\\\")\n",
        "\n",
        "        # Redimensionne les images\n",
        "        img = Image.open(img_path)\n",
        "        img = img.resize((img_size[0], img_size[1]), Image.ANTIALIAS)\n",
        "        img = np.asarray(img, dtype=\"float32\") # float32 pour conv\n",
        "        \n",
        "        images_train.append(img)\n",
        "\n",
        "        target = np.array([1 if csv_train.loc[path][c] == 1.0 else 0 for c in classes])\n",
        "        targets_train.append(target)\n",
        "                \n",
        "        \n",
        "    # Barre de chargement\n",
        "    done = i/to_do\n",
        "    print(\"Fetching : {}% |{}| {}/{}\".format(int(done*1000)/10, \"#\"*int(done*20) + \"-\"*(20-int(done*20)), i, to_do), end=\"\\r\")\n",
        "    i+=1\n",
        "    \n",
        "    if i >=max_size:\n",
        "        break\n",
        "\n",
        "# Test\n",
        "for path in csv_test.index:\n",
        "    \n",
        "    # On ne traite que les images frontales\n",
        "    if csv_test.loc[path][\"Frontal/Lateral\"] == \"Frontal\":\n",
        "    \n",
        "        img_path = \"{}/{}\".format(dataset_dir.split(\"CheXpert-v1.0-small\")[0], path).replace(\"/\", \"\\\\\")\n",
        "\n",
        "        # Redimensionne les images\n",
        "        img = Image.open(img_path)\n",
        "        img = img.resize((img_size[0], img_size[1]), Image.ANTIALIAS)\n",
        "        img = np.asarray(img, dtype=\"float32\") # float32 pour conv\n",
        "        \n",
        "        images_test.append(img)\n",
        "\n",
        "        target = np.array([1 if csv_test.loc[path][c] == 1.0 else 0 for c in classes])\n",
        "        targets_test.append(target)\n",
        "                \n",
        "\n",
        "    # Barre de chargement\n",
        "    done = i/to_do\n",
        "    print(\"Fetching : {}% |{}| {}/{}\".format(int(done*1000)/10, \"#\"*int(done*20) + \"-\"*(20-int(done*20)), i, to_do), end=\"\\r\")\n",
        "    i+=1\n",
        "\n",
        "print()\n",
        "\n",
        "### Pré-processing des données ###\n",
        "print(\"Preprocessing...\", end=\"\\r\")\n",
        "\n",
        "images_train = np.array(images_train)\n",
        "targets_train = np.array(targets_train)\n",
        "images_test = np.array(images_test)\n",
        "targets_test = np.array(targets_test)\n",
        "\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "scaled_images_train = scaler.fit_transform(images_train.reshape(-1, img_size[0]*img_size[1]*img_size[2]))\n",
        "scaled_images_test = scaler.transform(images_test.reshape(-1, img_size[0]*img_size[1]*img_size[2]))\n",
        "\n",
        "scaled_images_train = scaled_images_train.reshape(-1, img_size[0], img_size[1], img_size[2])\n",
        "scaled_images_test = scaled_images_test.reshape(-1, img_size[0], img_size[1], img_size[2])\n",
        "\n",
        "print(\"# Data Ready ! #\")"
      ],
      "id": "80f2d637-800e-4493-a898-1242f5db9567",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-15039a5565e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Récupère les fichiers csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcsv_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/train.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcsv_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/valid.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/arthu/datasets/CheXpert-v1.0-small/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1ef1847-b224-40a3-a53e-178af992a3d9"
      },
      "source": [
        "## Model"
      ],
      "id": "b1ef1847-b224-40a3-a53e-178af992a3d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3218a82e-945a-4406-8186-dccea7188de5"
      },
      "source": [
        "#### AlexNet"
      ],
      "id": "3218a82e-945a-4406-8186-dccea7188de5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14720823-9170-4a75-929e-2b2696bbbf7c"
      },
      "source": [
        "model_AlexNet = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224, 224, 1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(classes), activation='sigmoid')\n",
        "], name=\"AlexNet\")"
      ],
      "id": "14720823-9170-4a75-929e-2b2696bbbf7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83967d27-f8f5-49d6-a767-9f887faa2606"
      },
      "source": [
        "#### VGG16"
      ],
      "id": "83967d27-f8f5-49d6-a767-9f887faa2606"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22f132ef-ac27-4e72-9900-50d1813a07de"
      },
      "source": [
        "model_VGG16 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding=\"same\", input_shape=(224, 224, 1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "    \n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(classes), activation='sigmoid')\n",
        "], name=\"VGG16\")"
      ],
      "id": "22f132ef-ac27-4e72-9900-50d1813a07de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b814727-c600-4a64-915a-dc81ec9d1643"
      },
      "source": [
        "#### DenseNet"
      ],
      "id": "1b814727-c600-4a64-915a-dc81ec9d1643"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2ddfbaa-2663-4792-8845-6715c42e7001"
      },
      "source": [
        "model_DenseNet = None"
      ],
      "id": "a2ddfbaa-2663-4792-8845-6715c42e7001",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3054571-bcf8-4e03-8eb7-6e5353e0e872"
      },
      "source": [
        "### Setting up the model"
      ],
      "id": "a3054571-bcf8-4e03-8eb7-6e5353e0e872"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6aa2436-9c20-41da-8ec3-7800ccbb72da"
      },
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "id": "e6aa2436-9c20-41da-8ec3-7800ccbb72da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "698731b8-2479-4ea4-8a59-e92ab1bf290d"
      },
      "source": [
        "On utilise BinaryCrossentropy car la prédiction finale n'est pas réduite à une seule classe mais bien à plusieurs.\n",
        "\n",
        "L -> nombre de classes\n",
        "p = [p1, ..., pL] -> prediction\n",
        "t = [t1, ..., tL] -> target\n",
        "\n",
        "Loss = -1/L * Somme{ ti*log(pi) + (1-ti)*log(1-pi) }\n",
        "\n",
        "Si ti = 1 -> seul le terme ti*log(pi) compte, on veut maximiser (il faut pi = 1)\n",
        "Si ti = 0 -> seul le terme (1-ti)*log(1-pi) compte, on veut maximiser (il faut 1-pi = 1)\n",
        "\n",
        "On divise par L parce que, à l'inverse de CategoricalCrossentropy, il n'y a pas 1 valeur qui compte dans la somme mais bien toutes.\n",
        "\n",
        "Le -1 permet de diminuer le loss et non de l'augmenter."
      ],
      "id": "698731b8-2479-4ea4-8a59-e92ab1bf290d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ec6c47a-0fb8-4f45-80dd-d339f5ae7dc4"
      },
      "source": [
        "### Compile models"
      ],
      "id": "9ec6c47a-0fb8-4f45-80dd-d339f5ae7dc4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98895983-0872-4950-a3c8-77f176a1b06d",
        "outputId": "4e17f40e-a638-4647-e63f-ae7f3b2a82bf"
      },
      "source": [
        "# AlexNet\n",
        "model_AlexNet.compile(\n",
        "    loss=loss_object,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "model_AlexNet.summary()\n",
        "\n",
        "# VGG16\n",
        "model_VGG16.compile(\n",
        "    loss=loss_object,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "model_VGG16.summary()"
      ],
      "id": "98895983-0872-4950-a3c8-77f176a1b06d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"AlexNet\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 54, 54, 96)        11712     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 54, 54, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 384)       885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 12, 12, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 12, 12, 256)       884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4096)              26218496  \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 12)                49164     \n",
            "=================================================================\n",
            "Total params: 46,778,444\n",
            "Trainable params: 46,775,692\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n",
            "Model: \"VGG16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 224, 224, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 224, 224, 64)      256       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 224, 224, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 224, 224, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 112, 112, 128)     512       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 112, 112, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 112, 112, 128)     512       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 112, 112, 128)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 56, 56, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 56, 56, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 56, 56, 256)       1024      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 56, 56, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 28, 28, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 28, 28, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 28, 28, 512)       2048      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 28, 28, 512)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 12)                49164     \n",
            "=================================================================\n",
            "Total params: 26,576,588\n",
            "Trainable params: 26,571,212\n",
            "Non-trainable params: 5,376\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97fe22a6-32c6-4b1a-8ee5-6739b0923b9c"
      },
      "source": [
        "## Training"
      ],
      "id": "97fe22a6-32c6-4b1a-8ee5-6739b0923b9c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3869d5bc-9824-4a92-8874-d10eb40982dd",
        "outputId": "4558b59b-07dd-4714-efdc-cb1e580932b5"
      },
      "source": [
        "epochs = 1\n",
        "batch_size = 32\n",
        "model = model_VGG16\n",
        "\n",
        "history = model.fit(scaled_images_train, targets_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
      ],
      "id": "3869d5bc-9824-4a92-8874-d10eb40982dd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2/100 [..............................] - ETA: 25:51 - loss: 1.0773 - accuracy: 0.0625"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-20-87a6fa9568b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_VGG16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_images_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32mc:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\arthu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b649696a-5ec6-4d6b-8c0f-38684abdb827"
      },
      "source": [
        "### Visualization"
      ],
      "id": "b649696a-5ec6-4d6b-8c0f-38684abdb827"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abdffdcc-bab2-4960-bfc7-9b51b846f35b",
        "outputId": "8ce6fcb4-513e-425b-a135-eab46e70b2f3"
      },
      "source": [
        "loss_curve = history.history[\"loss\"]\n",
        "acc_curve = history.history[\"accuracy\"]\n",
        "\n",
        "loss_val_curve = history.history[\"val_loss\"]\n",
        "acc_val_curve = history.history[\"val_accuracy\"]\n",
        "\n",
        "plt.plot(loss_curve, \"r\", label=\"Train\")\n",
        "plt.plot(loss_val_curve, \"g\", label=\"Validation\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(acc_curve, \"r\", label=\"Train\")\n",
        "plt.plot(acc_val_curve, \"g\", label=\"Validation\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "id": "abdffdcc-bab2-4960-bfc7-9b51b846f35b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}